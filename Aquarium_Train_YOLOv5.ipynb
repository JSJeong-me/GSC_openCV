{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GSC_openCV/blob/main/Aquarium_Train_YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie5uLDH4uzAp",
        "outputId": "124f7356-921e-4dc9-c356-6e0107267f0b"
      },
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 13687, done.\u001b[K\n",
            "remote: Counting objects: 100% (489/489), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 13687 (delta 354), reused 435 (delta 310), pack-reused 13198\u001b[K\n",
            "Receiving objects: 100% (13687/13687), 13.29 MiB | 18.49 MiB/s, done.\n",
            "Resolving deltas: 100% (9413/9413), done.\n",
            "/content/yolov5/yolov5\n",
            "HEAD is now at fbe67e4 Fix `OMP_NUM_THREADS=1` for macOS (#8624)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72de342a-2e62-47d0-84b1-727cac3443e1"
      },
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.12.1+cu113 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knxi2ncxWffW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4d0155d-63c9-4c2c-a63e-a553ecbef611"
      },
      "source": [
        "#follow the link below to get your download code from from Roboflow\n",
        "!pip install -q roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolov5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 178 kB 7.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 21.6 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 68.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 72.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 55.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 68.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=roboflow-yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug_PhK1oqwQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0aa346b-dba5-4973-ec14-20e0b8703f10"
      },
      "source": [
        "%cd /content/yolov5\n",
        "#after following the link above, recieve python code with these fields filled in\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n",
        "#project = rf.workspace().project(\"YOUR PROJECT\")\n",
        "#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IHbJXTarX4C-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bwGn2UQlX4qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "w9qlzHPeYZfu",
        "outputId": "93c4067a-252a-40b0-c590-5274650d3e3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Aquarium_Combined.v1i.yolov5pytorch.zip ."
      ],
      "metadata": {
        "id": "_pFNZvINX1ua"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Aquarium_Combined.v1i.yolov5pytorch.zip"
      ],
      "metadata": {
        "id": "48QxbviAYEyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.location='/content/'"
      ],
      "metadata": {
        "id": "8pk6f8QlXvFU",
        "outputId": "1e08a92c-0caf-43cb-bbee-84461d3e4f17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2bb2d199cf63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ3DmmGQztJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0acb3aff-719d-48df-e307-b47a0bc3e0f8"
      },
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat ./data.yaml"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "nc: 7\n",
            "names: ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Define Model Configuration and Architecture\n",
        "\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
        "\n",
        "You do not need to edit these cells, but you may."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(\"./data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rvt5wilnDyX"
      },
      "source": [
        "#this is the model configuration we will use for our tutorial \n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Train Custom YOLOv5 Detector\n",
        "\n",
        "### Next, we'll fire off training!\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n",
        "- **name:** result names\n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 100 --data ./data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C60XAsyv6OPe"
      },
      "source": [
        "# we can also output some older school graphs if the tensor board isn't working for whatever reason... \n",
        "from utils.plots import plot_results  # plot results.txt as results.png\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLI1JmHU7B0l"
      },
      "source": [
        "### Curious? Visualize Our Training Data with Labels\n",
        "\n",
        "After training starts, view `train*.jpg` images to see training images, labels and augmentation effects.\n",
        "\n",
        "Note a mosaic dataloader is used for training (shown below), a new dataloading concept developed by Glenn Jocher and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF9MLHDb7tB6"
      },
      "source": [
        "# first, display our ground truth data\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/test_batch0_labels.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W40tI99_7BcH"
      },
      "source": [
        "# print out an augmented training example\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3qM6T0W53gh"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIEwt5YLeQ7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d042529c-2d05-49e1-f53c-a8aac20eaab7"
      },
      "source": [
        "# trained weights are saved by default in our weights folder\n",
        "%ls runs/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SyOWS80qR32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ece1df-82ed-4db9-eb7c-7de938ee493c"
      },
      "source": [
        "%ls runs/train/yolov5s_results/weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best.pt  last.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nmZZnWOgJ2S"
      },
      "source": [
        "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
        "# use the best weights!\n",
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source ../test/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKEqYtTgbRc"
      },
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uPq9mVgiBql"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4CTzDRh00g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcac05aa-7bb2-40bb-d1ba-cf8b2d30a4f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x_wg3VeiXMW"
      },
      "source": [
        "%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpCFeU-K4gb"
      },
      "source": [
        "## Congrats!\n",
        "\n",
        "Hope you enjoyed this!\n",
        "\n",
        "--Team [Roboflow](https://roboflow.ai)"
      ]
    }
  ]
}